{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3640f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "#from torch_geometric.data import Dataset, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94257aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetamatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        \"\"\"\n",
    "        Custom dataset for 3D graph data with 'Young' as the label.\n",
    "\n",
    "        Args:\n",
    "            data_list (list): List of dictionaries containing 'Nodal positions', 'Edge index', and 'Young'.\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single graph data object.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the data to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing node positions, edge index, and Young's modulus.\n",
    "        \"\"\"\n",
    "        entry = self.data_list[idx]\n",
    "        nodal_positions = torch.tensor(entry['Nodal positions'], dtype=torch.float).squeeze()\n",
    "        edge_index = torch.tensor(entry['Edge index'], dtype=torch.long).squeeze().t().contiguous()\n",
    "        young = torch.tensor(entry['Young'], dtype=torch.float)\n",
    "\n",
    "        return {\n",
    "            'x': nodal_positions,\n",
    "            'edge_index': edge_index,\n",
    "            'y': young\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7539b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SimpleGCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SimpleGCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        num_nodes = x.size(0)\n",
    "        # Build adjacency matrix from edge_index\n",
    "        adj = torch.zeros((num_nodes, num_nodes), device=x.device)\n",
    "        adj[edge_index[0], edge_index[1]] = 1\n",
    "        # Add self-loops\n",
    "        adj += torch.eye(num_nodes, device=x.device)\n",
    "        # Normalize adjacency\n",
    "        deg = adj.sum(dim=1)\n",
    "        deg_inv_sqrt = torch.pow(deg, -0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        D_inv_sqrt = torch.diag(deg_inv_sqrt)\n",
    "        adj_norm = D_inv_sqrt @ adj @ D_inv_sqrt\n",
    "        x = self.linear(x)\n",
    "        out = adj_norm @ x\n",
    "        return out\n",
    "\n",
    "class PredictorGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(PredictorGNN, self).__init__()\n",
    "        self.gcn1 = SimpleGCNLayer(input_dim, hidden_dim)\n",
    "        self.gcn2 = SimpleGCNLayer(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gcn1(x, adj)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gcn2(x, adj)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.mean(x, dim=0)  # Global mean pooling\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ccbb669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pkl_file(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "ini_data = read_pkl_file(\"/home/wzhan24/MetaMatDiff/datacreate/data.pkl\")\n",
    "ini_data = [item for item in ini_data if 'Young' in item and 'Nodal positions' in item and 'Edge index' in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b14104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 10333\n",
      "Validation dataset size: 3444\n",
      "Test dataset size: 3445\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = MetamatDataset(ini_data)\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "batch_size = 1  # Use 1 for graph data unless you implement batching\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10871a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   1,  20,  10,   4,   2,  32,  32,  62,  61,  59,  22,  21,  35,\n",
       "          40,  72,  61,  16,  60,  60,  90,  41,  71,  63,   4,  20,  10,  24,\n",
       "          44,   2,  26,  11,  67,  56,  16,  22,  73,  17,  21,  70,  34,  84,\n",
       "          55,  72,  45,  71,  85,  69,   7,  24,   4,  50,  22,  11,  14,  47,\n",
       "          46,  73,  21,  70,  80,  75,  76,  71,   1,  10,  22,   4,   2,  23,\n",
       "          11,  59,  21,  22,  35,  17,  70,  16,  70,  90,  25,  19,  71,  74,\n",
       "           0,  27,  43,  30,   7,  56,  52,  26,  14,  47,  68,  34,  75,  38,\n",
       "          84,  53,  54,  45,  83,  77,  18,  82,  86,  69,  27,   6,   7,  28,\n",
       "          44,  48,   3,  52,  67,  14,  47,  78,  46,   5,  13,  53,  75,  83,\n",
       "          36,  76,  77,  79,  49,  82,  43,   9,  50,  48,  15,  68,  78,  46,\n",
       "          47,  80,  75,  76,   1,   2,   0,   3,   4,  10, 102,  11,  16, 106,\n",
       "           6,   9,   3,  13,  12,   8,   5,  15, 116,   7,   6,  13,  14, 122,\n",
       "          17,  19,   8,  18,  20,  24,   4,  22,  23,  17,  21,  25,   1,  30,\n",
       "          28,  35,   3,  40,  23,  36,   0,   1,  27,  32,  20,  31,  38,  40,\n",
       "           2,  12,  23,  29,  37,  39,  35,  41,  32,  20,  35,  40, 164,   0,\n",
       "          26,  33,  42,  29,  38,  37,  34,  33,  27,  30,  28,  42,  38,  31,\n",
       "          26,  37, 183,  12,  39,  34,  40,  91,  16,  90,  41,  19,  89,  92,\n",
       "           8,  61,  25,  79,  19,  86,  49,  74,  17,   5,  61,  51,  54,  25,\n",
       "          72,  77,  18,  19,  58,  63,  92,  74,  88,  81,  23,  21,  61,  25,\n",
       "          60,  72,  41,  71,  89,  63,  92,  74,  46,  55,  39,  76,  36,  58,\n",
       "          49,  85,  66,  51,  54,  18,  45,  95,  69,  81,   5,  29,  66,  51,\n",
       "          54,  55,  53,  36,  77,  79,  45,  58,  86,  49,  95,  69,  82,  85,\n",
       "          88,  81, 268, 270],\n",
       "        [ 10,   2,  24,  11,  17,  11,  59,  35,  73,  62,  70,  25,  23,  70,\n",
       "          91,  73,  72,  19,  71,  63,  92,  89,  74,  74,   6,  33,  43,  48,\n",
       "          62,  42,  32,  13,  91,  59,  68,  65,  78,  66,  64,  93,  41,  90,\n",
       "          60,  95,  63,  94,  89,  92,  10,  57,   9,  62,  52,  15,  16,  59,\n",
       "          60,  87,  53,  83,  91,  90,  89,  82,  20,  24,  24,  62,  40,  32,\n",
       "          91,  62,  59,  60,  41,  61,  73,  73,  89,  91,  63,  72,  90,  92,\n",
       "          33,  28,  50,  31,  44,  57,  64,  29,  67,  48,  80,  37,  78,  42,\n",
       "          87,  65,  66,  51,  94,  79,  95,  93,  88,  81,  30,   9,  43,  31,\n",
       "          50,  57,  12,  65,  80,  68,  56,  87,  55,   8,  15,  64,  84,  93,\n",
       "          39,  85,  86,  88,  58,  94,  57,  44,  56,  52,  67,  87,  83,  65,\n",
       "          64,  84,  94,  93,  96,  97,  98,  99, 100, 101, 103, 104, 105, 107,\n",
       "         108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 123,\n",
       "         124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
       "         138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
       "         152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 165, 166,\n",
       "         167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
       "         181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "         266, 267, 269, 271]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['edge_index']  # Example to access edge index of the first graph in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a3b0012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.00001884\n",
      "Epoch 2/10, Loss: 0.00000125\n",
      "Validation Loss after Epoch 2: 0.00000206\n",
      "Epoch 3/10, Loss: 0.00000118\n",
      "Epoch 4/10, Loss: 0.00000119\n",
      "Validation Loss after Epoch 4: 0.00000085\n",
      "Epoch 5/10, Loss: 0.00000115\n",
      "Epoch 6/10, Loss: 0.00000115\n",
      "Validation Loss after Epoch 6: 0.00000100\n",
      "Epoch 7/10, Loss: 0.00000115\n",
      "Epoch 8/10, Loss: 0.00000115\n",
      "Validation Loss after Epoch 8: 0.00000112\n",
      "Epoch 9/10, Loss: 0.00000113\n",
      "Epoch 10/10, Loss: 0.00000112\n",
      "Validation Loss after Epoch 10: 0.00000148\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, optimizer, and loss function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PredictorGNN(input_dim=3, hidden_dim=64, output_dim=3).to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop with validation\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            x = batch['x'].to(device)\n",
    "            edge_index = batch['edge_index'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x[0], edge_index[0])\n",
    "            loss = criterion(output.squeeze(), y.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.8f}\")\n",
    "\n",
    "        # Validate every 5 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    x = batch['x'].to(device)\n",
    "                    edge_index = batch['edge_index'].to(device)\n",
    "                    y = batch['y'].to(device)\n",
    "                    output = model(x[0], edge_index[0])\n",
    "                    loss = criterion(output.squeeze(), y.squeeze())\n",
    "                    val_loss += loss.item()\n",
    "            print(f\"Validation Loss after Epoch {epoch+1}: {val_loss/len(val_loader):.8f}\")\n",
    "            model.train()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
